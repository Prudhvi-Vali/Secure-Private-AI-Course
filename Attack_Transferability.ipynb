{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transferability.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQ2PmsY283WU",
        "outputId": "6bc6d0e0-84c0-4b74-f7a4-0c299c90e918"
      },
      "source": [
        "#%tensorflow_version 1.x\n",
        "#!git clone https://github.com/tensorflow/cleverhans.git\n",
        "!pip install cleverhans\n",
        "!pip install adversarial-robustness-toolbox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cleverhans\n",
            "  Downloading cleverhans-4.0.0-py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 155 kB/s \n",
            "\u001b[?25hCollecting pycodestyle\n",
            "  Downloading pycodestyle-2.8.0-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 921 kB/s \n",
            "\u001b[?25hRequirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.9)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from cleverhans) (0.12.0)\n",
            "Collecting mnist\n",
            "  Downloading mnist-0.2.2-py2.py3-none-any.whl (3.5 kB)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.7/dist-packages (from cleverhans) (0.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from cleverhans) (3.2.2)\n",
            "Collecting nose\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[K     |████████████████████████████████| 154 kB 24.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (3.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (2.8.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (0.1.6)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (0.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (1.3.0)\n",
            "Installing collected packages: pycodestyle, nose, mnist, cleverhans\n",
            "Successfully installed cleverhans-4.0.0 mnist-0.2.2 nose-1.3.7 pycodestyle-2.8.0\n",
            "Collecting adversarial-robustness-toolbox\n",
            "  Downloading adversarial_robustness_toolbox-1.8.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (4.62.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (57.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn<1.1.0,>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.19.5)\n",
            "Collecting numba>=0.53.1\n",
            "  Downloading numba-0.54.1-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 34.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Collecting llvmlite<0.38,>=0.37.0rc1\n",
            "  Downloading llvmlite-0.37.0-cp37-cp37m-manylinux2014_x86_64.whl (26.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.3 MB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial-robustness-toolbox) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<1.1.0,>=0.22.2->adversarial-robustness-toolbox) (1.1.0)\n",
            "Installing collected packages: llvmlite, numba, adversarial-robustness-toolbox\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed adversarial-robustness-toolbox-1.8.1 llvmlite-0.37.0 numba-0.54.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DrTwTGfBazl"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from art.estimators.classification import KerasClassifier\n",
        "from art.utils import load_dataset\n",
        "import random\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Activation, Dropout, BatchNormalization\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "#from cleverhans.compat import softmax_cross_entropy_with_logits\n",
        "#from cleverhans.utils_keras import KerasModelWrapper\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DIyGaFs61ZxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CIFAR-10 Dataset\n",
        "(x_train_victim, y_train_victim), (x_test_victim, y_test_victim), min_, max_ = load_dataset(str(\"cifar10\")) # Original Dataset\n",
        "print(\"x_train_victim shape: \" + str(x_train_victim.shape) + \"\\n\" + \"x_train_victim size: \" + str(x_train_victim.size) + \"\\n\" + # this print statement is used for understanding what the CIFAR-10 dataset is\n",
        "      \"y_train_victim shape: \" + str(y_train_victim.shape) + \"\\n\" + \"y_train_victim size: \" + str(y_train_victim.size) + \"\\n\" +\n",
        "      \"x_test_victim shape: \" + str(x_test_victim.shape) + \"\\n\" + \"x_test_victim size: \" + str(x_test_victim.size) + \"\\n\" +\n",
        "      \"y_test_victim shape: \" + str(y_test_victim.shape) + \"\\n\" + \"y_test_victim size: \" + str(y_test_victim.size) + \"\\n\")\n",
        "print()\n",
        "\n",
        "\n",
        "#  Load the victim model\n",
        "classifier_url =\"https://tfhub.dev/deepmind/ganeval-cifar10-convnet/1\" #@param {type:\"string\"} # model is downloaded from this site\n",
        "IMAGE_SHAPE = (32, 32) # the image shape is needed so that the model knows the input-shape and since we are working with the CIFAR-10 all the images are 32 x 32 color images\n",
        "victim_classifier = KerasClassifier(model=tf.keras.Sequential([hub.KerasLayer(classifier_url, input_shape=IMAGE_SHAPE+(3,))]), clip_values=(min_, max_)) # this bascially creates a keras wrapper around the downloaded model so that we can use it with keras functions.\n",
        "\n",
        "\n",
        "# Evaluating the victim model on the benign dataset\n",
        "predictions = victim_classifier.predict(x_test_victim) # giving the classifier the x_test of the CIFAR-10 dataset.\n",
        "accuracy_benign = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test_victim, axis=1)) / len(y_test_victim) # calculates the accuracy of the predictions\n",
        "print(\"Accuracy on benign test examples for victim classifier: {}%\\n\".format(accuracy_benign * 100))\n"
      ],
      "metadata": {
        "id": "uRgTDbod1Xgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmkSM0g_GHyE",
        "outputId": "cd342225-4c4a-4a59-90c7-7907d00209d0"
      },
      "source": [
        "#  Collect subset\n",
        "def exract_subset(data, labels):\n",
        "    x_pre = []  \n",
        "    y_pre = []  \n",
        "    #count = 0\n",
        "    for index in range(0, len(data)):  \n",
        "        x_pre.append(data[index])  \n",
        "        y_predict = np.argmax(victim_classifier.predict( data[index].reshape( (1, data[index].shape[ 0 ], data[index].shape[ 1 ], data[index].shape[ 2 ]) ) ) )  # add the image label to the y_test set\n",
        "        y_pre.append(y_predict)\n",
        "       \n",
        "    x = np.asarray(x_pre)  \n",
        "    y = keras.utils.to_categorical(np.asarray(y_pre), 10)  \n",
        "    return x, y\n",
        "\n",
        "X_subset, Y_subset = exract_subset( x_test_victim, y_test_victim )\n",
        "print(\"X_subset shape: \" + str(X_subset.shape) + \"\\n\" + \"X_subset size: \" + str(X_subset.size) + \"\\n\" +\n",
        "      \"Y_subset shape: \" + str(Y_subset.shape) + \"\\n\" + \"Y_subset size: \" + str(Y_subset.size) + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_subset shape: (10000, 32, 32, 3)\n",
            "X_subset size: 30720000\n",
            "Y_subset shape: (10000, 10)\n",
            "Y_subset size: 100000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1NU-2c6zJvj",
        "outputId": "15572922-cea2-40ff-e387-bcc45719198d"
      },
      "source": [
        "!apt-get install cleverhans"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "E: Unable to locate package cleverhans\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JIOGhCmrBac"
      },
      "source": [
        "Up to this point the victim classifer has been evaluted on the test set of cifar10 = 94.5% accuracy, and the test set has been extracted with the labels given by the victim model's predtiction, i.e. 10000 examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hdaJHUsLVrM",
        "outputId": "2ee8d4a1-d76c-4c47-cd33-f780fe40daf4"
      },
      "source": [
        "X =X_subset\n",
        "Y = Y_subset\n",
        "x_train_substitute = X[:7500]\n",
        "y_train_substitute = Y[:7500]\n",
        "print(\"x_train_substitute shape: \" + str(x_train_substitute.shape) + \"\\n\" + \"x_train_substitute size: \" + str(x_train_substitute.size) + \"\\n\" + \n",
        "      \"y_train_substitute shape: \" + str(y_train_substitute.shape) + \"\\n\" + \"y_train_substitute size: \" + str(y_train_substitute.size) + \"\\n\")\n",
        "print()\n",
        "\n",
        "x_test_substitute = X[7500:]\n",
        "y_test_substitute = Y[7500:]\n",
        "print(\"x_test_substitute shape: \" + str(x_test_substitute.shape) + \"\\n\" + \"x_test_substitute size: \" + str(x_test_substitute.size) + \"\\n\" + \n",
        "      \"y_test_substitute shape: \" + str(y_test_substitute.shape) + \"\\n\" + \"y_test_substitute size: \" + str(y_test_substitute.size) + \"\\n\")\n",
        "print()\n",
        "\n",
        "\n",
        "#  Creating the model\n",
        "model_substitute = Sequential()\n",
        "model_substitute.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=x_train_substitute.shape[1:]))\n",
        "model_substitute.add(Activation(\"relu\"))\n",
        "model_substitute.add(Conv2D(32, (3, 3)))\n",
        "model_substitute.add(Activation(\"relu\"))\n",
        "model_substitute.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_substitute.add(Dropout(0.25))\n",
        "\n",
        "model_substitute.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model_substitute.add(Activation(\"relu\"))\n",
        "model_substitute.add(Conv2D(64, (3, 3)))\n",
        "model_substitute.add(Activation(\"relu\"))\n",
        "model_substitute.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_substitute.add(Dropout(0.25))\n",
        "\n",
        "model_substitute.add(Flatten())\n",
        "model_substitute.add(Dense(512))\n",
        "model_substitute.add(Activation(\"relu\"))\n",
        "model_substitute.add(Dropout(0.5))\n",
        "model_substitute.add(Dense(10))\n",
        "model_substitute.add(Activation(\"softmax\"))\n",
        "\n",
        "model_substitute.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "\n",
        "# Step 3: Creating the classifier\n",
        "substitute_classifier = KerasClassifier(model=model_substitute, clip_values=(0., 1.))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train_substitute shape: (7500, 32, 32, 3)\n",
            "x_train_substitute size: 23040000\n",
            "y_train_substitute shape: (7500, 10)\n",
            "y_train_substitute size: 75000\n",
            "\n",
            "\n",
            "x_test_substitute shape: (2500, 32, 32, 3)\n",
            "x_test_substitute size: 7680000\n",
            "y_test_substitute shape: (2500, 10)\n",
            "y_test_substitute size: 25000\n",
            "\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3JDApld2YoQ"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKGkIK_V2Ywh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkNLPh19LVyV",
        "outputId": "da16f67b-3512-4db1-c0ac-15ea152f4fa1"
      },
      "source": [
        "def one_hot(value):\n",
        "  vec = np.zeros((10))\n",
        "  vec[value] = 1\n",
        "  return vec\n",
        "\n",
        "def jacobian(predictions, inputs, num_classes):\n",
        "    #That is, how does the kth element of yhat vary wrt x?\n",
        "    return [tf.gradients(predictions[:, c], inputs)[0] for c in range(0, num_classes)]\n",
        "\n",
        "def jacobian_prediction_dimension(grads, predictions):\n",
        "    return [grads[predictions[i]][i] for i in np.arange(len(predictions))]\n",
        "\n",
        "wrapper = KerasClassifier( model_substitute ) # create keras wrapper for substitute model\n",
        "adv_train_epochs = 1 # run the loop for 2 runs genreating 22500 samples from 7500 samples\n",
        "adv_train_set = x_train_substitute / 255.0 # assign the varaible adv_train_set the x_train which holds 7500 samples\n",
        "\n",
        "\n",
        "for adv_train_epoch in range(adv_train_epochs): # loop for syntehtic data generation\n",
        "    print(\"RUN: \" + str(adv_train_epoch))\n",
        "    print(\"Before: \")\n",
        "    print(adv_train_set.shape) # initial size of the x_train (7500, 32, 32, 3)\n",
        "\n",
        "    # Get labels from victim model and train substitute model\n",
        "    oracle_labels = victim_classifier.predict(adv_train_set) # have the victim model label the x_train values, i.e. getting the y_train labels = 7500 labels\n",
        "    print(\"Oracle Predict: \")\n",
        "    print(oracle_labels.shape) # shape of the y_train = (7500, 10)\n",
        "    substitute_classifier.fit(adv_train_set, oracle_labels, nb_epochs=10, batch_size=128) # fit the substitute model with the training set created thus far.    \n",
        "\n",
        "    # Convert the labels from victim model to one hot encoded vectors\n",
        "    oracle_labels = np.zeros((adv_train_set.shape[0],10))\n",
        "    for i in range(0,x_train_substitute.shape[0]):\n",
        "        oracle_labels[i] = one_hot(np.argmax(victim_classifier.predict( adv_train_set[i].reshape( (1, adv_train_set[i].shape[ 0 ], adv_train_set[i].shape[ 1 ], adv_train_set[i].shape[ 2 ]) ) )))\n",
        "    print(\"Inside Augment: \" + str(oracle_labels.shape))\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RUN: 0\n",
            "Before: \n",
            "(7500, 32, 32, 3)\n",
            "Oracle Predict: \n",
            "(7500, 10)\n",
            "Epoch 1/10\n",
            "7500/7500 [==============================] - 19s 3ms/step - loss: -4681832998268008.0000 - accuracy: 0.9863\n",
            "Epoch 2/10\n",
            "7500/7500 [==============================] - 19s 3ms/step - loss: -8404932867181074.0000 - accuracy: 0.9875\n",
            "Epoch 3/10\n",
            "7500/7500 [==============================] - 19s 3ms/step - loss: -14249379158178206.0000 - accuracy: 0.9876\n",
            "Epoch 4/10\n",
            "7500/7500 [==============================] - 19s 3ms/step - loss: -23043457454749988.0000 - accuracy: 0.9864\n",
            "Epoch 5/10\n",
            "7500/7500 [==============================] - 19s 3ms/step - loss: -35760463533504848.0000 - accuracy: 0.9877\n",
            "Epoch 6/10\n",
            "7500/7500 [==============================] - 19s 3ms/step - loss: -53634649193476648.0000 - accuracy: 0.9881\n",
            "Epoch 7/10\n",
            "7500/7500 [==============================] - 19s 3ms/step - loss: -77940428083473776.0000 - accuracy: 0.9881\n",
            "Epoch 8/10\n",
            "7500/7500 [==============================] - 19s 3ms/step - loss: -110631488075768848.0000 - accuracy: 0.9873\n",
            "Epoch 9/10\n",
            "7500/7500 [==============================] - 19s 3ms/step - loss: -153755490560567168.0000 - accuracy: 0.9883\n",
            "Epoch 10/10\n",
            "7500/7500 [==============================] - 19s 3ms/step - loss: -208502648381208928.0000 - accuracy: 0.9872\n",
            "Inside Augment: (7500, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNAiD2eqmMa2"
      },
      "source": [
        "    # Create a session\n",
        "    with tf.Session() as sess:\n",
        "        xm = model_substitute.layers[0].input \n",
        "        yhat = wrapper.get_logits( xm )\n",
        "        init = tf.global_variables_initializer()\n",
        "        sess = tf.Session( )   \n",
        "        sess.run(init) # Initializes the variables\n",
        "        grads = sess.run(jacobian(yhat, xm, 10), feed_dict={xm: adv_train_set}) # compute the grads with the jacobian function\n",
        "        jpd = jacobian_prediction_dimension(grads, np.argmax(oracle_labels, 1))\n",
        "\n",
        "    perturbed_set = []\n",
        "    jbda_lambda = 0.1\n",
        "    tau = 1\n",
        "    jbda_epoch_lambda = jbda_lambda * np.power(-1, np.floor(adv_train_epoch/tau))\n",
        "    for idx, example in enumerate(adv_train_set):\n",
        "        new_example = example + jbda_epoch_lambda * (np.sign(jpd[idx]))\n",
        "        perturbed_set.append(new_example)\n",
        "    adv_train_set = np.vstack((adv_train_set, np.array(perturbed_set)))\n",
        "\n",
        "    print(\"After: \")\n",
        "    print(adv_train_set.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "COWjZnOofiP8",
        "outputId": "0e142e93-72e2-426d-d3b9-eca1bfd5ec77"
      },
      "source": [
        "print(adv_train_set.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(15000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsCZtvT52ZVG",
        "outputId": "a49351c9-0549-4f8a-969a-ce25687559c4"
      },
      "source": [
        "# Collect subset\n",
        "def exract_subset(data):\n",
        "    x_pre = []  \n",
        "    y_pre = []  \n",
        "    #count = 0\n",
        "    for index in range(0, len(data)):  \n",
        "        x_pre.append(data[index])  \n",
        "        y_predict = np.argmax(victim_classifier.predict( data[index].reshape( (1, data[index].shape[ 0 ], data[index].shape[ 1 ], data[index].shape[ 2 ]) ) ) )  # add the image label to the y_test set\n",
        "        y_pre.append(y_predict)\n",
        "        #if y_predict != np.argmax(labels[index]):\n",
        "            #print(str(np.argmax(labels[index])) + \" : \" + str(y_predict))\n",
        "            #count = count + 1\n",
        "    #print(count)\n",
        "    x = np.asarray(x_pre)  \n",
        "    y = keras.utils.to_categorical(np.asarray(y_pre), 10)  \n",
        "    return x, y\n",
        "\n",
        "X_synthetic, Y_synthetic = exract_subset( adv_train_set )\n",
        "print(\"X_synthetic shape: \" + str(X_synthetic.shape) + \"\\n\" + \"X_synthetic size: \" + str(X_synthetic.size) + \"\\n\" +\n",
        "      \"Y_synthetic shape: \" + str(Y_synthetic.shape) + \"\\n\" + \"Y_synthetic size: \" + str(Y_synthetic.size) + \"\\n\")\n",
        "\n",
        "#np.save('/content/gdrive/My Drive/X_synthetic', X_synthetic) \n",
        "#np.save('/content/gdrive/My Drive/Y_synthetic', Y_synthetic) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_synthetic shape: (7500, 32, 32, 3)\n",
            "X_synthetic size: 23040000\n",
            "Y_synthetic shape: (7500, 10)\n",
            "Y_synthetic size: 75000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfyT_wUmfq4K",
        "outputId": "cb3ae4f1-786e-4b28-9041-ff0fbc652adf"
      },
      "source": [
        "#X_train = np.load('/content/gdrive/My Drive/X_synthetic.npy') \n",
        "#Y_train = np.load('/content/gdrive/My Drive/Y_synthetic.npy') \n",
        "#print(\"X shape: \" + str(X.shape) + \"\\n\" + \"X size: \" + str(X.size) + \"\\n\" + \n",
        "#      \"Y shape: \" + str(Y.shape) + \"\\n\" + \"Y size: \" + str(Y.size) + \"\\n\")\n",
        "#print()\n",
        "X_train = X_synthetic\n",
        "Y_train = Y_synthetic\n",
        "\n",
        "substitute_classifier.fit(X_train, Y_train, nb_epochs=10, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7500/7500 [==============================] - 19s 2ms/step - loss: 31304155450.5728 - accuracy: 0.9897\n",
            "Epoch 2/10\n",
            "7500/7500 [==============================] - 19s 2ms/step - loss: 34639197573.3931 - accuracy: 0.9888\n",
            "Epoch 3/10\n",
            "7500/7500 [==============================] - 19s 2ms/step - loss: 29232477993.9157 - accuracy: 0.9915\n",
            "Epoch 4/10\n",
            "7500/7500 [==============================] - 19s 2ms/step - loss: 21465745466.0267 - accuracy: 0.9925\n",
            "Epoch 5/10\n",
            "7500/7500 [==============================] - 19s 2ms/step - loss: 22619373681.5957 - accuracy: 0.9936\n",
            "Epoch 6/10\n",
            "7500/7500 [==============================] - 19s 2ms/step - loss: 12121543033.9243 - accuracy: 0.9951\n",
            "Epoch 7/10\n",
            "7500/7500 [==============================] - 19s 2ms/step - loss: 11402851839.7269 - accuracy: 0.9952\n",
            "Epoch 8/10\n",
            "7500/7500 [==============================] - 19s 2ms/step - loss: 8420498132.1728 - accuracy: 0.9965\n",
            "Epoch 9/10\n",
            "7500/7500 [==============================] - 18s 2ms/step - loss: 7832588692.1387 - accuracy: 0.9968\n",
            "Epoch 10/10\n",
            "7500/7500 [==============================] - 19s 2ms/step - loss: 9248997323.5712 - accuracy: 0.9973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHHU1w5i2ZZ7",
        "outputId": "1a115b0f-6428-43b7-cd3a-8f45ddb71e71"
      },
      "source": [
        "#Evaluate the ART classifier on benign test examples\n",
        "predictions = substitute_classifier.predict(x_test_substitute)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test_substitute, axis=1)) / len(y_test_substitute)\n",
        "print(\"Accuracy on benign test examples for substitute classifier: {}%\".format(accuracy * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on benign test examples for substitute classifier: 10.639999999999999%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GXsltyL2aA_"
      },
      "source": [
        "substitute_classifier.save(\"/content/gdrive/My Drive/Attack_Transfer_Substitute_Classifier_V3.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "nvEjpFHCtqVl",
        "outputId": "2047ab53-5d98-4ba3-e587-b64d59fbee23"
      },
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: adversarial-robustness-toolbox in /usr/local/lib/python3.6/dist-packages (1.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.4.1)\n",
            "Requirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (46.1.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (1.18.3)\n",
            "Requirement already satisfied: scikit-learn==0.22.1 in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (0.22.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from adversarial-robustness-toolbox) (3.2.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.22.1->adversarial-robustness-toolbox) (0.14.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->adversarial-robustness-toolbox) (2.4.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmNwHPC6uMUs"
      },
      "source": [
        "import art\n",
        "from art.classifiers import KerasClassifier\n",
        "tf.compat.v1.disable_eager_execution()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv0poHGh2aHf"
      },
      "source": [
        "\n",
        "from art.attacks import FastGradientMethod\n",
        "\n",
        "fgsm = FastGradientMethod(classifier=substitute_classifier)\n",
        "x_adversarial_fgsm = fgsm.generate(x_train_substitute,y_train_substitute)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZlOXKgX5zAYf",
        "outputId": "3a4c8535-6a3d-450c-8d8f-ba5a8f201caa"
      },
      "source": [
        "predictions = substitute_classifier.predict(x_test_substitute)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_test_substitute, axis=1)) / len(y_test_substitute)\n",
        "print(\"Accuracy on original examples for substitute classifier: {}%\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on original examples for substitute classifier: 0.1064%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vBjeYvRquwfn",
        "outputId": "e4fab6fd-70ce-4fd4-ee75-97264ac38f6b"
      },
      "source": [
        "predictions = substitute_classifier.predict(x_adversarial_fgsm)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_train_substitute, axis=1)) / len(y_train_substitute)\n",
        "print(\"Accuracy on adversarial exales for substitute classifier:{}\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on adversarial exales for substitute classifier:0.09906666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEfS3Pygzpmg"
      },
      "source": [
        "victim_classifier = KerasClassifier(model=model_substitute, clip_values=(0., 1.))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "QGAnS3Pdzxdc",
        "outputId": "0e130b63-8b1c-4c19-9989-a0e3600302b3"
      },
      "source": [
        "predictions = victim_classifier.predict(x_adversarial_fgsm) # giving the classifier the x_test of the CIFAR-10 dataset.\n",
        "accuracy_benign = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_train_substitute, axis=1)) / len(y_train_substitute) # calculates the accuracy of the predictions\n",
        "print(\"Accuracy on benign test examples for victim classifier: {}%\\n\".format(accuracy_benign * 100))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on benign test examples for victim classifier: 9.906666666666666%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6R-8WOW1tSg"
      },
      "source": [
        "from art.attacks import SaliencyMapMethod\n",
        "\n",
        "sm = SaliencyMapMethod(classifier=substitute_classifier)\n",
        "x_adversarial_sm = fgsm.generate(x_train_substitute,y_train_substitute)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FBXRrZf713xf",
        "outputId": "265332f1-9c98-48cc-d2a8-839089c218ba"
      },
      "source": [
        "predictions = substitute_classifier.predict(x_adversarial_sm)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(y_train_substitute, axis=1)) / len(y_train_substitute)\n",
        "print(\"Accuracy on original examples for substitute classifier: {}%\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on original examples for substitute classifier: 9.906666666666666%\n"
          ]
        }
      ]
    }
  ]
}